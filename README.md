# Recipe Improviser ‚Äì API Serverless com ChatGPT
Uma **API serverless** constru√≠da com **AWS Lambda + API Gateway**, capaz de gerar receitas culin√°rias com base nos ingredientes informados pelo usu√°rio.  
A gera√ß√£o das receitas utiliza a **API do OpenAI (ChatGPT)** com diferentes estilos e restri√ß√µes alimentares.  

Projeto desenvolvido como exemplo pr√°tico de integra√ß√£o entre **Serverless + IA**.

---

## üìë Sum√°rio

1. [Funcionalidades](#-funcionalidades)  
2. [Pr√©-requisitos](#Ô∏è-pr√©-requisitos)  
3. [Deploy na AWS Lambda](#-deploy-na-aws-lambda)  
4. [Endpoints da API](#-endpoints-da-api)  
   - [Healthcheck](#healthcheck)  
   - [Gerar Receita](#gerar-receita)  
5. [Limita√ß√£o Arquitetural](#Ô∏è-limita√ß√£o-arquitetural) 

---

## Funcionalidades

- ‚úÖ Gera√ß√£o de receitas a partir de ingredientes informados  
- ‚úÖ Suporte a **estilos** (simple, funny, gourmet, chaotic)  
- ‚úÖ Suporte a **restri√ß√µes alimentares** (vegan, vegetarian, gluten-free, lactose-free, low-cost)  
- ‚úÖ Endpoint de sa√∫de (`GET /health`)  
- ‚úÖ Modo offline para testes (ignora chamada √† OpenAI)  
- ‚úÖ Empacotamento simples em um √∫nico Lambda  

---

## Pr√©-requisitos

Antes de come√ßar, voc√™ precisa ter:  

- Conta na **AWS** (Lambda + API Gateway)  
- **Node.js 18+** instalado  
- **AWS CLI** configurado (`aws configure`)  
- Chave da **API OpenAI** configurada como vari√°vel de ambiente:  

---

## Deploy na AWS Lambda
1. [Empacotar c√≥digo](#1-empacotar-para-deploy)
2. [Criar fun√ß√£o Lambda](#2-criar-fun√ß√£o-lambda)
3. [Configurar API Gateway](#3-configurar-api-gateway)

---

### 1. Empacotar para deploy

### macOS/Linux
```bash
zip -r function.zip index.mjs package.json
```

### Windows (PowerShell)
```bash
Compress-Archive -Path index.mjs,package.json -DestinationPath function.zip -Force
```

--
## 2. Criar fun√ß√£o Lambda

1. **Acesse o [Console AWS Lambda](https://console.aws.amazon.com/lambda/)**
2. **Create function** ‚Üí "Author from scratch":
   - üîß **Runtime**: Node.js 22.x
   - üìõ **Nome**: `recipe-improviser`
3. **Upload do pacote**:
   - Selecione "Upload from" ‚Üí ".zip file"
   - Escolha o arquivo `function.zip` criado anteriormente
4. **Configurar vari√°veis de ambiente**:
   - `OPENAI_API_KEY`: sua chave da OpenAI
   - (Opcional) `SKIP_OPENAI`: `1` para modo de teste

## 3. Configurar API Gateway

1. Na fun√ß√£o Lambda criada:
   - Clique em **Add trigger**
2. Selecione **API Gateway**:
   - **Tipo**: HTTP API
   - **Seguran√ßa**: Open (para desenvolvimento)
3. **Configurar rotas**:
   - `GET /health` (healthcheck)
   - `POST /recipe` (endpoint principal)
4. Ap√≥s cria√ß√£o:
   - Anote a **URL de invoca√ß√£o** (ex: `https://[id].execute-api.[region].amazonaws.com`)

---
## üì° Endpoints da API

### Healthcheck

**M√©todo:** `GET`  
**Endpoint:** `/health`  
**Resposta:** 
```json
{
  "ok": true
}
```

### Gerar Receita

**M√©todo:** `POST`  
**Endpoint:** `/recipe`    
**Body de exemplo** 
```json
{
  "ingredients": ["tomate", "queijo", "macarr√£o"],
  "servings": 2,
  "style": "gourmet",
  "diet": "vegetarian"
}
```

**Resposta** 
```json
{
    "title": "Macarr√£o ao Molho de Tomate e Queijo",
    "servings": 2,
    "time_minutes": 25,
    "ingredients_used": [
        "200g de macarr√£o",
        "2 tomates maduros",
        "100g de queijo (pode ser mu√ßarela ou queijo parmes√£o)"
    ],
    "steps": [
        "1. Cozinhe o macarr√£o em √°gua salgada fervente at√© ficar al dente, seguindo as instru√ß√µes da embalagem.",
        "2. Enquanto o macarr√£o cozinha, lave os tomates e corte-os em cubos pequenos.",
        "3. Em uma panela, adicione um fio de azeite e refogue os tomates em fogo m√©dio at√© que comecem a desmanchar, cerca de 5 minutos.",
        "4. Adicione o macarr√£o cozido √† panela com os tomates e misture bem. Se necess√°rio, acrescente um pouco da √°gua do cozimento para soltar o molho.",
        "5. Rale o queijo e adicione √† mistura, mexendo at√© derreter e incorporar ao molho.",
        "6. Tempere com sal e pimenta a gosto e sirva quente."
    ],
    "tips": [
        "Para um toque especial, adicione manjeric√£o fresco ou or√©gano ao molho.",
        "Se preferir um molho mais cremoso, adicione um pouco de creme de leite ou uma colher de sopa de manteiga no final."
    ],
    "warnings": [
        "Certifique-se de cozinhar o macarr√£o at√© que esteja completamente cozido.",
        "Verifique se voc√™ n√£o tem alergia a algum dos ingredientes, especialmente ao queijo."
    ]
}
```
---
## Limita√ß√£o Arquitetural

Atualmente, a API segue um fluxo **s√≠ncrono**:

| #  | Componente      | A√ß√£o                         |
|----|----------------|-------------------------------|
| 1  | Cliente        | Envia requisi√ß√£o HTTP         |
| 2  | API Gateway    | Roteia para Lambda            |
| 3  | Lambda         | Processa entrada              |
| 4  | ChatGPT API    | Gera conte√∫do (7,5s)          |
| 5  | Lambda         | Formata resposta              |
| 6  | API Gateway    | Retorna HTTP                  |
| 7  | Cliente        | Recebe resposta               |


- A Lambda fica bloqueada aguardando a resposta do ChatGPT.  
- Tempo m√©dio de resposta: ~7,5 segundos por requisi√ß√£o.  
- Isso aumenta tanto o custo (Lambda cobra por dura√ß√£o) quanto o tempo de espera do usu√°rio.  

### Para reduzir custos e melhorar a experi√™ncia:
- Adotar processamento **ass√≠ncrono** (ex.: SQS + Lambda Worker).  
- Usar **Step Functions** para orquestrar fluxos mais longos.  
- Implementar **cache** em DynamoDB ou S3 para receitas populares.  
- Explorar **respostas em streaming** quando dispon√≠vel no API Gateway.  



